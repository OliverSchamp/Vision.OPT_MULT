{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from olv_object_detection import load_object_detector\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import easyocr\n",
    "from typing import List, Tuple, Dict\n",
    "from do_lines_intersect import do_lines_intersect\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path(\"/home/oliver/Oliver.Mono/projects/Vision.OPT_MULT/data/full_images/baekeland_1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(cv2.imread(str(image_path)), cv2.COLOR_BGR2GRAY)\n",
    "img_cropped = img[200:-200, 100:-100]\n",
    "plt.imshow(img_cropped, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en'])  # 'en' is for English; you can add more languages\n",
    "# Perform OCR on the image\n",
    "results: List[Tuple[List[List[int]], str, float]] = reader.readtext(img_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_box_lines = []\n",
    "for result in results:\n",
    "    for i, box_corner in enumerate(result[0]):\n",
    "        ocr_box_lines.append([result[0][i%4], result[0][(i+1)%4]])\n",
    "    if \"No\" in result[1]:\n",
    "        no_box_y_coord = result[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.GaussianBlur(img_cropped, (5, 5), 0)\n",
    "edges = cv2.Canny(image, 50, 150, apertureSize=3)\n",
    "lines = cv2.HoughLines(edges,1,np.pi/180,215, None, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all lines that cross through more than 4 ocr box lines\n",
    "h, w = image.shape[:2]\n",
    "\n",
    "intersection_counts_dict = {i:0 for i in range(len(lines))}\n",
    "for line_idx, line in enumerate(lines):\n",
    "    rho,theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 2*w*(-b))\n",
    "    y1 = int(y0 + 2*h*(a))\n",
    "    x2 = int(x0 - 2*w*(-b))\n",
    "    y2 = int(y0 - 2*h*(a))\n",
    "\n",
    "    for ocr_box_line in ocr_box_lines:\n",
    "        ocr_box_line_input = [ocr_box_line[0][0], ocr_box_line[0][1], ocr_box_line[1][0], ocr_box_line[1][1]]\n",
    "\n",
    "        if do_lines_intersect(ocr_box_line_input, [x1, y1, x2, y2]):\n",
    "            intersection_counts_dict[line_idx] += 1\n",
    "\n",
    "indices_to_remove = []\n",
    "\n",
    "for line_idx in intersection_counts_dict:\n",
    "    if intersection_counts_dict[line_idx] > 10:\n",
    "        indices_to_remove.append(line_idx)\n",
    "\n",
    "lines = np.delete(lines, indices_to_remove, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.GaussianBlur(img_cropped, (5, 5), 0)\n",
    "# edges = cv2.Canny(image, 50, 150, apertureSize=3)\n",
    "# lines = cv2.HoughLines(edges,1,np.pi/180,230, None, 0, 0)\n",
    "\n",
    "to_filter = True\n",
    "\n",
    "# idea: iteratively increase the rho and theta thresholds, and score lines based on points\n",
    "# always take the line with the more points\n",
    "\n",
    "# rho_theta_thresholds = [(0.1, 0.01), (1, 0.1), (3, 0.2), (7, 0.3), (10, 0.4), (20, 0.5), (30, 0.6), (40, 0.7)]\n",
    "\n",
    "# for rho_threshold, theta_threshold in rho_theta_thresholds:\n",
    "#     if to_filter:\n",
    "#         pass\n",
    "\n",
    "# tactic: put them all into theta ranges\n",
    "\n",
    "# theta_range_dict = {(i, j):0 for i, j in zip(np.linspace(0, np.pi, 200)[:-1], np.linspace(0, np.pi, 200)[1:])}\n",
    "\n",
    "# print(len(lines))\n",
    "\n",
    "# for i in range(len(lines)):\n",
    "#     rho_i,theta_i = lines[i][0]\n",
    "\n",
    "#     for theta_range in theta_range_dict:\n",
    "#         if theta_i <= theta_range[1] and theta_i > theta_range[0]:\n",
    "#             theta_range_dict[theta_range] += 1\n",
    "#             break\n",
    "\n",
    "# # print(f\"number of non-zero bins: {sum(np.array(list(theta_range_dict.values())) > 0)}\")\n",
    "\n",
    "# # for theta_range in theta_range_dict:\n",
    "# #     if theta_range_dict[theta_range] > 0:\n",
    "# #         print(f\"Range: {theta_range} Counts: {theta_range_dict[theta_range]}\")\n",
    "\n",
    "# sorted_theta_range_dict = dict(sorted(theta_range_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# ranges_to_accept = list(sorted_theta_range_dict.keys())[:1]\n",
    "\n",
    "# # currently, just accept horizontal and vertical\n",
    "\n",
    "# # ranges_to_accept = [(0, 0.1), (np.pi/2 -0.1, np.pi/2 + 0.1)]\n",
    "\n",
    "# print(ranges_to_accept)\n",
    "\n",
    "# indices_to_delete = []\n",
    "# for i in range(lines.shape[0]):\n",
    "#     outside_of_range1 = lines[i][0][1] <= ranges_to_accept[0][0] or lines[i][0][1] >= ranges_to_accept[0][1]\n",
    "#     outside_of_range2 = lines[i][0][1] <= ranges_to_accept[1][0] or lines[i][0][1] >= ranges_to_accept[1][1]\n",
    "\n",
    "#     if outside_of_range1 and outside_of_range2:\n",
    "#         indices_to_delete.append(i)\n",
    "#     else:\n",
    "#         if not outside_of_range1:\n",
    "#             print(f\"Inside {ranges_to_accept[0]}\")\n",
    "#         if not outside_of_range2:\n",
    "#             print(f\"Inside {ranges_to_accept[1]}\")\n",
    "\n",
    "# lines = np.delete(lines, indices_to_delete, axis=0)\n",
    "\n",
    "if to_filter:\n",
    "    rho_threshold = 40\n",
    "    theta_threshold = 0.7\n",
    "\n",
    "    # how many lines are similar to a given one\n",
    "    similar_lines = {i : [] for i in range(len(lines))}\n",
    "    for i in range(len(lines)):\n",
    "        for j in range(len(lines)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            \n",
    "            lines[i][0][0] = np.abs(lines[i][0][0])\n",
    "            lines[j][0][0] = np.abs(lines[j][0][0])\n",
    "\n",
    "            rho_i,theta_i = lines[i][0]\n",
    "            rho_j,theta_j = lines[j][0]\n",
    "\n",
    "            if abs(rho_i - rho_j) < rho_threshold and (abs(theta_i - theta_j) < theta_threshold or (np.pi - abs(theta_i - theta_j)) < theta_threshold):\n",
    "                similar_lines[i].append(j)\n",
    "\n",
    "    # ordering the INDECES of the lines by how many are similar to them\n",
    "    indices = [i for i in range(len(lines))]\n",
    "    indices.sort(key=lambda x : len(similar_lines[x]))\n",
    "\n",
    "    # line flags is the base for the filtering\n",
    "    line_flags = len(lines)*[True]\n",
    "    for i in range(len(lines) - 1):\n",
    "        if not line_flags[indices[i]]: # if we already disregarded the ith element in the ordered list then we don't care (we will not delete anything based on it and we will never reconsider using this line again)\n",
    "            continue\n",
    "\n",
    "        for j in range(i + 1, len(lines)): # we are only considering those elements that had less similar line\n",
    "            if not line_flags[indices[j]]: # and only if we have not disregarded them already\n",
    "                continue\n",
    "\n",
    "            rho_i,theta_i = lines[indices[i]][0]\n",
    "            rho_j,theta_j = lines[indices[j]][0]\n",
    "            if abs(rho_i - rho_j) < rho_threshold and (abs(theta_i - theta_j) < theta_threshold or (np.pi - abs(theta_i - theta_j)) < theta_threshold):\n",
    "                line_flags[indices[j]] = False # if it is similar and have not been disregarded yet then drop it now\n",
    "\n",
    "print('number of Hough lines:', len(lines))\n",
    "\n",
    "filtered_lines = []\n",
    "\n",
    "if to_filter:\n",
    "    for i in range(len(lines)): # filtering\n",
    "        if line_flags[i]:\n",
    "            filtered_lines.append(lines[i])\n",
    "\n",
    "    print('Number of filtered lines:', len(filtered_lines))\n",
    "else:\n",
    "    filtered_lines = lines\n",
    "\n",
    "image_with_lines = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "filtered_lines_cartesian = []\n",
    "for line in filtered_lines:\n",
    "    rho,theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 2000*(-b))\n",
    "    y1 = int(y0 + 2000*(a))\n",
    "    x2 = int(x0 - 2000*(-b))\n",
    "    y2 = int(y0 - 2000*(a))\n",
    "\n",
    "    cv2.line(image_with_lines,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "    filtered_lines_cartesian.append([x1, y1, x2, y2])\n",
    "\n",
    "plt.imshow(image_with_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop all questions according to the coordinates\n",
    "# TODO: find the intersections for all lines, and use this to calculate the centres for answers for each question row later on\n",
    "\n",
    "from olv_primitives import Bbox\n",
    "\n",
    "# split into vertical and horizontal lines\n",
    "vertical_lines = []\n",
    "horizontal_lines = []\n",
    "\n",
    "for line in filtered_lines_cartesian:\n",
    "    if abs(line[0]-line[2]) > abs(line[1]-line[3]):\n",
    "        horizontal_lines.append(line)\n",
    "    else:\n",
    "        vertical_lines.append(line)\n",
    "# remove middle vertical lines\n",
    "vertical_lines = [vertical_line for vertical_line in vertical_lines if vertical_line[0] > 0]\n",
    "vertical_lines.sort(key=lambda x : x[0])\n",
    "# vertical_lines = [vertical_lines[0]] + [vertical_lines[-1]]\n",
    "\n",
    "# find the No. OCR coords\n",
    "horizontal_lines = [horizontal_line for horizontal_line in horizontal_lines if horizontal_line[1] > no_box_y_coord-70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def line_intersection(line1, line2):\n",
    "\n",
    "    x1, y1, x2, y2 = line1\n",
    "    x3, y3, x4, y4 = line2\n",
    "    # Calculate the denominators and numerators for intersection formula\n",
    "    denominator = (x1 - x2) * (y3 - y4) - (y1 - y2) * (x3 - x4)\n",
    "    if denominator == 0:\n",
    "        return None  # Lines are parallel or collinear\n",
    "\n",
    "    # Calculate the intersection point\n",
    "    intersect_x = ((x1 * y2 - y1 * x2) * (x3 - x4) - (x1 - x2) * (x3 * y4 - y3 * x4)) / denominator\n",
    "    intersect_y = ((x1 * y2 - y1 * x2) * (y3 - y4) - (y1 - y2) * (x3 * y4 - y3 * x4)) / denominator\n",
    "    \n",
    "    # Check if the intersection point is within both line segments\n",
    "    if (min(x1, x2) <= intersect_x <= max(x1, x2) and min(y1, y2) <= intersect_y <= max(y1, y2) and\n",
    "        min(x3, x4) <= intersect_x <= max(x3, x4) and min(y3, y4) <= intersect_y <= max(y3, y4)):\n",
    "        return (intersect_x, intersect_y)\n",
    "    \n",
    "    return None  # The intersection is outside the segment bounds\n",
    "\n",
    "def find_intersections(horizontal_lines: List[List[int]], vertical_lines: List[List[int]]) -> List[Bbox]:\n",
    "    # sort both\n",
    "    horizontal_lines.sort(key=lambda x: x[1])\n",
    "    vertical_lines.sort(key= lambda x: x[0])\n",
    "\n",
    "    intersection_points_by_idx = defaultdict(list)\n",
    "    for vline_idx, vertical_line in enumerate(vertical_lines):\n",
    "        for horizontal_line in horizontal_lines:\n",
    "            intersection_point = line_intersection(horizontal_line, vertical_line)\n",
    "\n",
    "            if intersection_point is not None:\n",
    "                intersection_points_by_idx[vline_idx].append(intersection_point)\n",
    "    \n",
    "    for vline_idx in intersection_points_by_idx:\n",
    "        assert len(intersection_points_by_idx[vline_idx]) == len(horizontal_lines)\n",
    "    \n",
    "    class_midpoints_by_horizontal_line = defaultdict(list)\n",
    "    for i in range(len(horizontal_lines)):\n",
    "        for vline_idx in intersection_points_by_idx:\n",
    "            if vline_idx == 0 or vline_idx == len(intersection_points_by_idx) - 1:\n",
    "                continue\n",
    "            class_midpoints_by_horizontal_line[i].append((intersection_points_by_idx[vline_idx][i][0] + intersection_points_by_idx[vline_idx+1][i][0])/2 - intersection_points_by_idx[0][i][0])\n",
    "    \n",
    "    coords1 = intersection_points_by_idx[0]\n",
    "    coords2 = intersection_points_by_idx[len(vertical_lines) - 1]\n",
    "    assert len(coords1) == len(coords2)\n",
    "    output = []\n",
    "    for i in range(len(coords1)):\n",
    "        try:\n",
    "            output.append((coords1[i], coords2[i+1]))\n",
    "        except IndexError:\n",
    "            pass\n",
    "    \n",
    "    output_parsed = [Bbox.from_absolute(xtl, ytl, xbr, ybr, w, h) for ((xtl, ytl), (xbr, ybr)) in output]\n",
    "\n",
    "    return output_parsed, class_midpoints_by_horizontal_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines = horizontal_lines + vertical_lines\n",
    "crop_bboxes, class_midpoints = find_intersections(horizontal_lines, vertical_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from olv_draw import draw_bbs, DrawParameters\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_with_boxes = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_GRAY2RGB))\n",
    "image_canvas = ImageDraw.Draw(image_pil)\n",
    "draw_parameters = DrawParameters(fill_color=None)\n",
    "\n",
    "draw_bbs(image_canvas, crop_bboxes, draw_parameters)\n",
    "\n",
    "plt.imshow(np.array(image_pil))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "cropped_image_save_path = Path(\"/home/oliver/Oliver.Mono/projects/Vision.OPT_MULT/data/cropped_data/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "def get_xcentres_for_each_answer(easyocr_detections: Tuple[List[int], str, float]) -> Dict[float, str]:\n",
    "    output = {}\n",
    "\n",
    "    for easyocr_detection in easyocr_detections:\n",
    "        output[easyocr_detection[0][0][0] + easyocr_detection[0][2][0]] = easyocr_detection[1]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_path = Path(\"/home/oliver/Oliver.Mono/projects/Vision.OPT_MULT/data/models/object_detection/yolov5/20241105/140517/model.detector\")\n",
    "detector = load_object_detector(detector_path)\n",
    "\n",
    "df_cols = ['A', 'B', 'C', 'D']\n",
    "df = pd.DataFrame(columns=df_cols)\n",
    "\n",
    "label_box = True\n",
    "image_image_folder = cropped_image_save_path / image_path.stem\n",
    "image_image_folder.mkdir(parents=True, exist_ok=True)\n",
    "for i, bbox in enumerate(crop_bboxes):\n",
    "    bbox_cropped_image = image[int(bbox.ytl):int(bbox.ybr), int(bbox.xtl):int(bbox.xbr)]\n",
    "    if label_box is True:\n",
    "        label_box = False\n",
    "        continue\n",
    "\n",
    "    centres_for_answers = {mid:cls for mid, cls in zip(class_midpoints[i], df_cols)}\n",
    "    new_row = {'A': \" \", 'B': \" \", 'C': \" \", 'D': \" \"}\n",
    "    detections = detector.infer_parsed(bbox_cropped_image)\n",
    "    for detection in detections:\n",
    "        if detection.conf < 0.7:\n",
    "            continue\n",
    "        centre_x = detection.mid.x\n",
    "        diff = np.Inf\n",
    "        for answer_x in centres_for_answers:\n",
    "            diff_ans = abs(centre_x-answer_x)\n",
    "            if diff_ans < diff:\n",
    "                answer = centres_for_answers[answer_x]\n",
    "                diff = diff_ans\n",
    "\n",
    "        new_row[answer] = \"X\"\n",
    "\n",
    "    df.loc[len(df)] = list(new_row.values())\n",
    "\n",
    "    image_name = reader.readtext(bbox_cropped_image)[0][1]\n",
    "    image_save_path = image_image_folder / f\"{image_name}.jpg\"\n",
    "\n",
    "    cv2.imwrite(str(image_save_path), bbox_cropped_image)\n",
    "\n",
    "# Create a plot and hide the axes\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 10))  # Set the figure size\n",
    "\n",
    "# Hide the axes\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "\n",
    "# Create the table and add it to the plot\n",
    "table = ax[0].table(cellText=df.values, colLabels=df.columns, loc='center', cellLoc='center', colColours=[\"lightgray\"]*df.shape[1])\n",
    "\n",
    "# Customize the table (optional)\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1.2, 1.2)\n",
    "\n",
    "ax[1].imshow(img_cropped, cmap=\"gray\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_folder_path = Path(\"/home/oliver/Oliver.Mono/projects/Vision.OPT_MULT/data/csvs\")\n",
    "\n",
    "csv_file_path = csv_folder_path /  f\"{image_path.stem}.csv\"\n",
    "\n",
    "\n",
    "df.to_csv(csv_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
