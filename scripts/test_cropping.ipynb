{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from olv_object_detection import load_object_detector\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import easyocr\n",
    "from typing import List, Tuple, Dict\n",
    "from do_lines_intersect import do_lines_intersect\n",
    "from pathlib import Path\n",
    "\n",
    "from olv_draw import draw_bbs, DrawParameters\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path(\"/home/oliver/Oliver.Mono/projects/Vision.OPT_MULT/data/full_images/images/hodgkin_ks4_1.jpg\")\n",
    "number_detector_path = Path(\"/home/oliver/Oliver.Mono/projects/Vision.OPT_MULT/data/full_image_models/object_detection/yolov5/20241112/180906/model.detector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(img, angle):\n",
    "    (height, width) = img.shape[:2]\n",
    "    (cent_x, cent_y) = (width // 2, height // 2)\n",
    "\n",
    "    mat = cv2.getRotationMatrix2D((cent_x, cent_y), -angle, 1.0)\n",
    "    cos = np.abs(mat[0, 0])\n",
    "    sin = np.abs(mat[0, 1])\n",
    "\n",
    "    n_width = int((height * sin) + (width * cos))\n",
    "    n_height = int((height * cos) + (width * sin))\n",
    "\n",
    "    mat[0, 2] += (n_width / 2) - cent_x\n",
    "    mat[1, 2] += (n_height / 2) - cent_y\n",
    "\n",
    "    return cv2.warpAffine(img, mat, (n_width, n_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(cv2.imread(str(image_path)), cv2.COLOR_BGR2GRAY)\n",
    "img_cropped = img[200:-200, 100:-100]\n",
    "\n",
    "# img_cropped = rotate(img_cropped, 10)\n",
    "\n",
    "plt.imshow(img_cropped, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_detector = load_object_detector(number_detector_path)\n",
    "\n",
    "number_detections = no_detector.infer_parsed(img_cropped, conf_thres=0.1)\n",
    "\n",
    "image_pil = Image.fromarray(cv2.cvtColor(img_cropped, cv2.COLOR_GRAY2RGB))\n",
    "image_canvas = ImageDraw.Draw(image_pil)\n",
    "draw_parameters = DrawParameters(fill_color=None)\n",
    "\n",
    "draw_bbs(image_canvas, number_detections, draw_parameters)\n",
    "\n",
    "plt.imshow(np.array(image_pil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_box_lines = []\n",
    "no_ocr_box_y_coords = []\n",
    "for number_bbox in number_detections:\n",
    "    bbox_as_array = number_bbox.as_array()\n",
    "    for i in range(len(bbox_as_array)):\n",
    "        ocr_box_lines.append([bbox_as_array[i%4], bbox_as_array[(i+1)%4]])\n",
    "        # ocr_box_lines.append(np.concatenate((bbox_as_array[i%4], bbox_as_array[(i+1)%4]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_box_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.GaussianBlur(img_cropped, (5, 5), 0)\n",
    "edges = cv2.Canny(image, 50, 150, apertureSize=3)\n",
    "lines = cv2.HoughLines(edges,1,np.pi/180,150, None, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove all lines that cross through any ocr box line\n",
    "# h, w = image.shape[:2]\n",
    "\n",
    "# intersection_counts_dict = {i:0 for i in range(len(lines))}\n",
    "# for line_idx, line in enumerate(lines):\n",
    "#     rho,theta = line[0]\n",
    "#     a = np.cos(theta)\n",
    "#     b = np.sin(theta)\n",
    "#     x0 = a*rho\n",
    "#     y0 = b*rho\n",
    "#     x1 = int(x0 + 2*w*(-b))\n",
    "#     y1 = int(y0 + 2*h*(a))\n",
    "#     x2 = int(x0 - 2*w*(-b))\n",
    "#     y2 = int(y0 - 2*h*(a))\n",
    "\n",
    "#     for ocr_box_line in ocr_box_lines:\n",
    "#         ocr_box_line_input = [ocr_box_line[0][0], ocr_box_line[0][1], ocr_box_line[1][0], ocr_box_line[1][1]]\n",
    "\n",
    "#         if do_lines_intersect(ocr_box_line_input, [x1, y1, x2, y2]):\n",
    "#             intersection_counts_dict[line_idx] += 1\n",
    "\n",
    "# indices_to_remove = []\n",
    "\n",
    "# for line_idx in intersection_counts_dict:\n",
    "#     if intersection_counts_dict[line_idx] > 2:\n",
    "#         indices_to_remove.append(line_idx)\n",
    "\n",
    "# lines = np.delete(lines, indices_to_remove, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = image.shape[:2]\n",
    "\n",
    "vertical_thetas = []\n",
    "horizontal_thetas = []\n",
    "for i in range(lines.shape[0]):\n",
    "    if lines[i][0][1] > np.pi/4 and lines[i][0][1] < (3*np.pi)/4:\n",
    "        horizontal_thetas.append(lines[i][0][1])\n",
    "    else:\n",
    "        vertical_thetas.append(lines[i][0][1])\n",
    "\n",
    "for i in range(len(vertical_thetas)):\n",
    "    if vertical_thetas[i] > np.pi/2:\n",
    "        vertical_thetas[i] -= np.pi\n",
    "\n",
    "# find the median values and remove outliers\n",
    "horizontal_thetas.sort()\n",
    "horizontal_theta = horizontal_thetas[len(horizontal_thetas)//2]\n",
    "\n",
    "vertical_theta = horizontal_theta - np.pi/2\n",
    "\n",
    "indices_to_delete = []\n",
    "for i in range(lines.shape[0]):\n",
    "    if abs(lines[i][0][1] - horizontal_theta) > np.pi/360 and abs(lines[i][0][1] - vertical_theta) > np.pi/360:\n",
    "        indices_to_delete.append(i)\n",
    "\n",
    "lines = np.delete(lines, indices_to_delete, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_filter = True\n",
    "\n",
    "if to_filter:\n",
    "    rho_threshold = 40\n",
    "    theta_threshold = 0.7\n",
    "\n",
    "    # how many lines are similar to a given one\n",
    "    similar_lines = {i : [] for i in range(len(lines))}\n",
    "    for i in range(len(lines)):\n",
    "        for j in range(len(lines)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            \n",
    "            lines[i][0][0] = np.abs(lines[i][0][0])\n",
    "            lines[j][0][0] = np.abs(lines[j][0][0])\n",
    "\n",
    "            rho_i,theta_i = lines[i][0]\n",
    "            rho_j,theta_j = lines[j][0]\n",
    "\n",
    "            if abs(rho_i - rho_j) < rho_threshold and (abs(theta_i - theta_j) < theta_threshold or (np.pi - abs(theta_i - theta_j)) < theta_threshold):\n",
    "                similar_lines[i].append(j)\n",
    "\n",
    "    # ordering the INDECES of the lines by how many are similar to them\n",
    "    indices = [i for i in range(len(lines))]\n",
    "    indices.sort(key=lambda x : len(similar_lines[x]))\n",
    "\n",
    "    # line flags is the base for the filtering\n",
    "    line_flags = len(lines)*[True]\n",
    "    for i in range(len(lines) - 1):\n",
    "        if not line_flags[indices[i]]: # if we already disregarded the ith element in the ordered list then we don't care (we will not delete anything based on it and we will never reconsider using this line again)\n",
    "            continue\n",
    "\n",
    "        for j in range(i + 1, len(lines)): # we are only considering those elements that had less similar line\n",
    "            if not line_flags[indices[j]]: # and only if we have not disregarded them already\n",
    "                continue\n",
    "\n",
    "            rho_i,theta_i = lines[indices[i]][0]\n",
    "            rho_j,theta_j = lines[indices[j]][0]\n",
    "            if abs(rho_i - rho_j) < rho_threshold and (abs(theta_i - theta_j) < theta_threshold or (np.pi - abs(theta_i - theta_j)) < theta_threshold):\n",
    "                line_flags[indices[j]] = False # if it is similar and have not been disregarded yet then drop it now\n",
    "\n",
    "print('number of Hough lines:', len(lines))\n",
    "\n",
    "filtered_lines = []\n",
    "\n",
    "if to_filter:\n",
    "    for i in range(len(lines)): # filtering\n",
    "        if line_flags[i]:\n",
    "            filtered_lines.append(lines[i])\n",
    "\n",
    "    print('Number of filtered lines:', len(filtered_lines))\n",
    "else:\n",
    "    filtered_lines = lines\n",
    "\n",
    "image_with_lines = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "filtered_lines_cartesian = []\n",
    "for line in filtered_lines:\n",
    "    rho,theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 4000*(-b))\n",
    "    y1 = int(y0 + 4000*(a))\n",
    "    x2 = int(x0 - 4000*(-b))\n",
    "    y2 = int(y0 - 4000*(a))\n",
    "\n",
    "    cv2.line(image_with_lines,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "    filtered_lines_cartesian.append([x1, y1, x2, y2])\n",
    "\n",
    "plt.imshow(image_with_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop all questions according to the coordinates\n",
    "# TODO: find the intersections for all lines, and use this to calculate the centres for answers for each question row later on\n",
    "\n",
    "from olv_primitives import Bbox\n",
    "\n",
    "# split into vertical and horizontal lines\n",
    "vertical_lines = []\n",
    "horizontal_lines = []\n",
    "\n",
    "for line in filtered_lines_cartesian:\n",
    "    if abs(line[0]-line[2]) > abs(line[1]-line[3]):\n",
    "        horizontal_lines.append(line)\n",
    "    else:\n",
    "        vertical_lines.append(line)\n",
    "# remove middle vertical lines\n",
    "vertical_lines = [vertical_line for vertical_line in vertical_lines if vertical_line[0] > 0]\n",
    "vertical_lines.sort(key=lambda x : x[0])\n",
    "num_vertical_lines = len(vertical_lines)\n",
    "# vertical_lines = [vertical_lines[0]] + [vertical_lines[-1]]\n",
    "\n",
    "# find the No. OCR coords\n",
    "horizontal_lines = [horizontal_line for horizontal_line in horizontal_lines] # if horizontal_line[1] > min(no_ocr_box_y_coords)-70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all lines that cross through any ocr box line\n",
    "h, w = image.shape[:2]\n",
    "\n",
    "intersection_counts_dict = {i:0 for i in range(len(lines))}\n",
    "for line_idx, line in enumerate(vertical_lines):\n",
    "    for ocr_box_line in ocr_box_lines:\n",
    "        ocr_box_line_input = [ocr_box_line[0][0], ocr_box_line[0][1], ocr_box_line[1][0], ocr_box_line[1][1]]\n",
    "\n",
    "        if do_lines_intersect(ocr_box_line_input, line):\n",
    "            intersection_counts_dict[line_idx] += 1\n",
    "\n",
    "indices_to_remove = []\n",
    "\n",
    "for line_idx in intersection_counts_dict:\n",
    "    if intersection_counts_dict[line_idx] > 0:\n",
    "        indices_to_remove.append(line_idx)\n",
    "\n",
    "vertical_lines = [vertical_line for idx, vertical_line in enumerate(vertical_lines) if idx not in indices_to_remove] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_with_lines2 = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "for line in vertical_lines:\n",
    "    x1, y1, x2, y2 = line\n",
    "    cv2.line(image_with_lines2,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "plt.imshow(image_with_lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_x(vertical_line: List[float]):\n",
    "    return (vertical_line[0] + vertical_line[2])/2\n",
    "\n",
    "vertical_line_spacing = [avg_x(vertical_lines[1:][i+1]) - avg_x(vertical_lines[1:][i]) for i in range(len(vertical_lines[1:])-1)]\n",
    "vertical_line_spacing.sort()\n",
    "vertical_line_median = vertical_line_spacing[len(vertical_lines[1:]) // 2]\n",
    "\n",
    "new_vertical_lines = [vertical_lines[1]]\n",
    "for i in range(len(vertical_lines[1:])):\n",
    "    predicted_xloc = new_vertical_lines[-1][0] + vertical_line_median\n",
    "    for vertical_line in vertical_lines:\n",
    "        if abs(avg_x(vertical_line) - predicted_xloc) < vertical_line_median/8:\n",
    "            new_vertical_lines.append(vertical_line)\n",
    "            break\n",
    "\n",
    "vertical_lines = [vertical_lines[0]] + new_vertical_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_line_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_with_lines2 = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "for line in vertical_lines:\n",
    "    x1, y1, x2, y2 = line\n",
    "    cv2.line(image_with_lines2,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "plt.imshow(image_with_lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def line_intersection(line1, line2):\n",
    "\n",
    "    x1, y1, x2, y2 = line1\n",
    "    x3, y3, x4, y4 = line2\n",
    "    # Calculate the denominators and numerators for intersection formula\n",
    "    denominator = (x1 - x2) * (y3 - y4) - (y1 - y2) * (x3 - x4)\n",
    "    if denominator == 0:\n",
    "        return None  # Lines are parallel or collinear\n",
    "\n",
    "    # Calculate the intersection point\n",
    "    intersect_x = ((x1 * y2 - y1 * x2) * (x3 - x4) - (x1 - x2) * (x3 * y4 - y3 * x4)) / denominator\n",
    "    intersect_y = ((x1 * y2 - y1 * x2) * (y3 - y4) - (y1 - y2) * (x3 * y4 - y3 * x4)) / denominator\n",
    "    \n",
    "    # Check if the intersection point is within both line segments\n",
    "    if (min(x1, x2) <= intersect_x <= max(x1, x2) and min(y1, y2) <= intersect_y <= max(y1, y2) and\n",
    "        min(x3, x4) <= intersect_x <= max(x3, x4) and min(y3, y4) <= intersect_y <= max(y3, y4)):\n",
    "        return (intersect_x, intersect_y)\n",
    "    \n",
    "    return None  # The intersection is outside the segment bounds\n",
    "\n",
    "def find_intersections(horizontal_lines: List[List[int]], vertical_lines: List[List[int]]) -> List[Bbox]:\n",
    "    # sort both\n",
    "    horizontal_lines.sort(key=lambda x: x[1])\n",
    "    vertical_lines.sort(key= lambda x: x[0])\n",
    "\n",
    "    intersection_points_by_idx = defaultdict(list)\n",
    "    for vline_idx, vertical_line in enumerate(vertical_lines):\n",
    "        for horizontal_line in horizontal_lines:\n",
    "            intersection_point = line_intersection(horizontal_line, vertical_line)\n",
    "\n",
    "            if intersection_point is not None:\n",
    "                intersection_points_by_idx[vline_idx].append(intersection_point)\n",
    "    \n",
    "    for vline_idx in intersection_points_by_idx:\n",
    "        assert len(intersection_points_by_idx[vline_idx]) == len(horizontal_lines)\n",
    "    \n",
    "    class_midpoints_by_horizontal_line = defaultdict(list)\n",
    "    for i in range(len(horizontal_lines)):\n",
    "        for vline_idx in intersection_points_by_idx:\n",
    "            if vline_idx == 0 or vline_idx == len(intersection_points_by_idx) - 1:\n",
    "                continue\n",
    "            class_midpoints_by_horizontal_line[i].append((intersection_points_by_idx[vline_idx][i][0] + intersection_points_by_idx[vline_idx+1][i][0])/2 - intersection_points_by_idx[0][i][0])\n",
    "    \n",
    "    coords1 = intersection_points_by_idx[0]\n",
    "    coords2 = intersection_points_by_idx[len(vertical_lines) - 1]\n",
    "    assert len(coords1) == len(coords2)\n",
    "    output = []\n",
    "    for i in range(len(coords1)):\n",
    "        try:\n",
    "            output.append((coords1[i], coords2[i+1]))\n",
    "        except IndexError:\n",
    "            pass\n",
    "    \n",
    "    output_parsed = [Bbox.from_absolute(xtl, ytl, xbr, ybr, w, h) for ((xtl, ytl), (xbr, ybr)) in output]\n",
    "\n",
    "    return output_parsed, class_midpoints_by_horizontal_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines = horizontal_lines + vertical_lines\n",
    "crop_bboxes, class_midpoints = find_intersections(horizontal_lines, vertical_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_with_boxes = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_GRAY2RGB))\n",
    "image_canvas = ImageDraw.Draw(image_pil)\n",
    "draw_parameters = DrawParameters(fill_color=None)\n",
    "\n",
    "draw_bbs(image_canvas, crop_bboxes, draw_parameters)\n",
    "\n",
    "plt.imshow(np.array(image_pil))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "cropped_image_save_path = Path(\"/home/oliver/Oliver.Mono/projects/Vision.OPT_MULT/data/cropped_data/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_path = Path(\"/home/oliver/Oliver.Mono/projects/Vision.OPT_MULT/data/models/object_detection/yolov5/20241106/192000/model.detector\")\n",
    "detector = load_object_detector(detector_path)\n",
    "\n",
    "df_cols = [chr(ord('A') + i) for i in range(num_vertical_lines - 2)]\n",
    "df = pd.DataFrame(columns=df_cols)\n",
    "\n",
    "label_box = True\n",
    "image_image_folder = cropped_image_save_path / image_path.stem\n",
    "image_image_folder.mkdir(parents=True, exist_ok=True)\n",
    "for i, bbox in enumerate(crop_bboxes):\n",
    "    bbox_cropped_image = image[int(bbox.ytl):int(bbox.ybr), int(bbox.xtl):int(bbox.xbr)]\n",
    "    if label_box is True:\n",
    "        label_box = False\n",
    "        continue\n",
    "\n",
    "    centres_for_answers = {mid:cls for mid, cls in zip(class_midpoints[i], df_cols)}\n",
    "    new_row = {col_value: \" \" for col_value in df_cols}\n",
    "    detections = detector.infer_parsed(bbox_cropped_image)\n",
    "\n",
    "    has_question_number = False\n",
    "    for detection in detections:\n",
    "        if detection.label == \"question_number\" and detection.mid.x < 200:\n",
    "            has_question_number = True\n",
    "    \n",
    "    if not has_question_number:\n",
    "        continue\n",
    "\n",
    "    for detection in detections:\n",
    "        if detection.conf < 0.63 or detection.label != \"answer\":\n",
    "            continue\n",
    "\n",
    "        centre_x = detection.mid.x\n",
    "        diff = np.Inf\n",
    "        for answer_x in centres_for_answers:\n",
    "            diff_ans = abs(centre_x-answer_x)\n",
    "            if diff_ans < diff:\n",
    "                answer = centres_for_answers[answer_x]\n",
    "                diff = diff_ans\n",
    "\n",
    "        new_row[answer] = \"X\"\n",
    "\n",
    "    df.loc[len(df)] = list(new_row.values())\n",
    "    # try:\n",
    "    #     image_name = reader.readtext(bbox_cropped_image)[0][1]\n",
    "    #     image_save_path = image_image_folder / f\"{image_name}.jpg\"\n",
    "\n",
    "    #     cv2.imwrite(str(image_save_path), bbox_cropped_image)\n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "# Create a plot and hide the axes\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 10))  # Set the figure size\n",
    "\n",
    "# Hide the axes\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "\n",
    "# Create the table and add it to the plot\n",
    "table = ax[0].table(cellText=df.values, colLabels=df.columns, loc='center', cellLoc='center', colColours=[\"lightgray\"]*df.shape[1])\n",
    "\n",
    "# Customize the table (optional)\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1.2, 1.2)\n",
    "\n",
    "ax[1].imshow(img_cropped, cmap=\"gray\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_folder_path = Path(\"/home/oliver/Oliver.Mono/projects/Vision.OPT_MULT/data/csvs\")\n",
    "\n",
    "# csv_file_path = csv_folder_path /  f\"{image_path.stem}.csv\"\n",
    "\n",
    "\n",
    "# df.to_csv(csv_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
